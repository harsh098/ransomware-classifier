{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvvoT0IzenFb",
    "outputId": "44e2d2c9-bbbe-4d9f-eb75-0b2abe1c7a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-Lki3uMdzlI7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jhWspWyOGMY0"
   },
   "outputs": [],
   "source": [
    "# time period to compute the rate of event\n",
    "# 1e9 nanoseconds = 1 second\n",
    "TIME_PERIOD = 1e9\n",
    "\n",
    "# TYPE_NAMES = ['open', 'create', 'delete', 'encrypt']\n",
    "TYPE_NAMES = ['O', 'C', 'D', 'E']\n",
    "\n",
    "# PID offset (to avoid duplicated PIDs across detector runs)\n",
    "PID_OFFSET = 1e4\n",
    "\n",
    "LOGDIR  = './logs/'\n",
    "DATADIR = './data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC3HgTUMr5eT"
   },
   "source": [
    "Flush `DATADIR` if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VvDNuPOjr_jg"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('./data', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wSJkjJncsHbd"
   },
   "outputs": [],
   "source": [
    "! mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JjZWkYY1raZm"
   },
   "outputs": [],
   "source": [
    "def counts(df):\n",
    "    # group by PID, TYPE and PERIOD\n",
    "    ts = df['TS']\n",
    "    df1 = df.assign(PERIOD=np.trunc((ts - ts[0]) / TIME_PERIOD))\n",
    "    df1.drop(columns=['TS', 'FLAG', 'OPEN', 'CREATE', 'DELETE', 'ENCRYPT', 'FILENAME'], inplace=True)\n",
    "\n",
    "    # count the number of event grouped by type, period and PID and move TYPE to column\n",
    "    grouped = df1.groupby(['TYPE', 'PERIOD', 'PID']).agg(['count','sum']).unstack(level='TYPE', fill_value=0)\n",
    "\n",
    "    # aggregate over time period (max per period + total)\n",
    "    aggregated = grouped.groupby(level='PID').agg(['max','sum'])\n",
    "\n",
    "    # rename levels/columns (skip 'PATTERN')\n",
    "    aggregated.columns = aggregated.columns.to_flat_index()\n",
    "    aggregated.rename(columns={col: '_'.join(col[1:]) for col in aggregated.columns}, inplace=True)\n",
    "\n",
    "    # sum the number of pattern matches across events\n",
    "    pattern_max = re.compile(\"^sum_\\w+_max$\")\n",
    "    pattern_sum = re.compile(\"^sum_\\w+_sum$\")\n",
    "    pattern_max_cols = [col for col in aggregated.columns if pattern_max.match(col)]\n",
    "    pattern_sum_cols = [col for col in aggregated.columns if pattern_sum.match(col)]\n",
    "    aggregated['P_max'] = aggregated[pattern_max_cols].sum(axis=1)\n",
    "    aggregated['P_sum'] = aggregated[pattern_sum_cols].sum(axis=1)\n",
    "    aggregated.drop(columns=pattern_max_cols + pattern_sum_cols, inplace=True)\n",
    "\n",
    "    # strip \"count_\" from columns starting with count\n",
    "    aggregated.rename(columns={col: col[6:] for col in aggregated.columns if col.startswith('count')}, inplace=True)\n",
    "\n",
    "    return aggregated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QnJfqs6ErkCo"
   },
   "outputs": [],
   "source": [
    "def sequences(df):\n",
    "    df1 = df.drop(columns=['FLAG', 'PATTERN', 'OPEN', 'CREATE', 'DELETE', 'ENCRYPT', 'FILENAME'])\n",
    "\n",
    "    # count the number of event type sequences (length 3)\n",
    "    df1['NEXT'] = df1.groupby(['PID'])['TYPE'].transform(lambda col: col.shift(-1, fill_value='X'))\n",
    "    df1['AFTER'] = df1.groupby(['PID'])['TYPE'].transform(lambda col: col.shift(-2, fill_value='X'))\n",
    "    df1['SEQUENCE'] = df1[['TYPE', 'NEXT', 'AFTER']].apply(lambda row: ''.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    aggregated = df1.groupby(['PID', 'SEQUENCE'])['TS'].agg('count').unstack(level='SEQUENCE', fill_value=0)\n",
    "\n",
    "    # drop dummy sequences (containing X)\n",
    "    aggregated.drop(columns=[col for col in aggregated.columns if 'X' in col], inplace=True)\n",
    "\n",
    "    return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3lpF1BSrng1",
    "outputId": "a64b7e3f-dae0-4b53-d96f-f4d6039b61f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-ae50ce7ab5c3>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TYPE'].replace([0,1,2,3], TYPE_NAMES, inplace=True)\n",
      "<ipython-input-23-ae50ce7ab5c3>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TYPE'].replace([0,1,2,3], TYPE_NAMES, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# process logs in training and testing directories\n",
    "# for dir in next(os.walk(LOGDIR))[1]:\n",
    "for dir in ['training', 'testing']:\n",
    "    # sort to keep PIDs unchanged when adding files\n",
    "    logs = sorted(glob.glob(LOGDIR + dir + '/*.csv'))\n",
    "\n",
    "    # PID collision fix (offset)\n",
    "    df_arr = []\n",
    "    for i,log in enumerate(logs):\n",
    "        df = pd.read_csv(log)\n",
    "        df['PID'] = df['PID'].map(lambda x: x + i * PID_OFFSET)\n",
    "        # df['FILE'] = log\n",
    "        df_arr.append(df)\n",
    "\n",
    "    df = pd.concat(df_arr, ignore_index=True, verify_integrity=True)\n",
    "\n",
    "    df['TYPE'].replace([0,1,2,3], TYPE_NAMES, inplace=True)\n",
    "\n",
    "    c = counts(df)\n",
    "    s = sequences(df)\n",
    "\n",
    "    combined = pd.concat([c, s], axis=1)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    # print(combined)\n",
    "\n",
    "    # save to csv\n",
    "    combined.to_csv(DATADIR + dir + '_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7XbgnDqsUP5"
   },
   "outputs": [],
   "source": [
    "df_output_columns = pd.read_csv(DATADIR + '/testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PID', 'C_max', 'C_sum', 'D_max', 'D_sum', 'E_max', 'E_sum', 'O_max',\n",
       "       'O_sum', 'P_max', 'P_sum', 'CCC', 'CCD', 'CCO', 'CDC', 'CDD', 'CDO',\n",
       "       'COC', 'COD', 'COO', 'DCC', 'DCD', 'DCO', 'DDC', 'DDD', 'DDO', 'DOC',\n",
       "       'DOD', 'DOO', 'EEE', 'EEO', 'EOE', 'EOO', 'OCC', 'OCD', 'OCO', 'ODC',\n",
       "       'ODD', 'ODO', 'OEE', 'OOC', 'OOD', 'OOO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_columns = pd.read_csv(LOGDIR + 'testing/2_revilog1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TS', 'PID', 'TYPE', 'FLAG', 'PATTERN', 'OPEN', 'CREATE', 'DELETE',\n",
       "       'ENCRYPT', 'FILENAME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
